{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a convolutional neural network (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will import the information stored as numpy arrays and create train/test and validation data sets. As we have imbalanced data due to the high abundance of beech trees in the data set, we will do data augmentation and oversampling. Next, we crate the structure for the models used for classification and look into the results and accuracy of our best model.\n",
    "\n",
    "While we tested different model structures and number of features, here, we will only report our best model.\n",
    "\n",
    "\n",
    "**Data you need for running this notebook:**\n",
    "\n",
    "Zipped numpy arrays (.npz) with all information, that should be added to the model (such as spectral information and vegetation height)\n",
    "\n",
    "**Content overview:**\n",
    "\n",
    "- Setup\n",
    "- Import and manipulate data\n",
    "- Split the data into a train, test and validation set\n",
    "- Perform data augmentation\n",
    "- Deal with class imbalance\n",
    "- Perform oversampling\n",
    "- One hot encoding\n",
    "- Hyperparameter search\n",
    "- Structure of the nsemble Model\n",
    "- Results\n",
    "\n",
    "\n",
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9g/jlj5g_zj4rg83ktdjhr98bf80000gn/T/ipykernel_26384/346208476.py:17: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  import kerastuner as kt\n"
     ]
    }
   ],
   "source": [
    "# Toolboxes for data handling\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Toolboxes for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Toolboxes for modelling with a neural network\n",
    "import tensorflow as tf\n",
    "import mlflow\n",
    "\n",
    "# Toolboxes for splitting the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Toolbox for hyperparameter tuning\n",
    "import kerastuner as kt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and manipulate data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basis for the modelling are the box images, that have been stored as zipped numpy arrays (from notebook XXX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../images/box_images/baseline/model_images.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m height_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m../images/box_images/baseline/model_images_vegheight.npz\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[39m# Load the image array containing all box images in a 4D array and their\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39m# labels\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39;49mload(data_path, allow_pickle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m) \u001b[39mas\u001b[39;00m data:\n\u001b[1;32m      8\u001b[0m     img_array \u001b[39m=\u001b[39m data[\u001b[39m\"\u001b[39m\u001b[39mimg_array\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m      9\u001b[0m     labels \u001b[39m=\u001b[39m data[\u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/numpy/lib/npyio.py:405\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    403\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 405\u001b[0m     fid \u001b[39m=\u001b[39m stack\u001b[39m.\u001b[39menter_context(\u001b[39mopen\u001b[39;49m(os_fspath(file), \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[1;32m    406\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    408\u001b[0m \u001b[39m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../images/box_images/baseline/model_images.npz'"
     ]
    }
   ],
   "source": [
    "# Define the path to the data file\n",
    "data_path = '../images/box_images/baseline/model_images.npz'\n",
    "height_path = '../images/box_images/baseline/model_images_vegheight.npz'\n",
    "\n",
    "# Load the image array containing all box images in a 4D array and their\n",
    "# labels\n",
    "with np.load(data_path, allow_pickle=True) as data:\n",
    "    img_array = data[\"img_array\"]\n",
    "    labels = data[\"labels\"]\n",
    "\n",
    "with np.load(height_path, allow_pickle=True) as data:\n",
    "    height_array_tmp = data[\"img_array\"]\n",
    "    labels_height = data[\"labels\"]\n",
    "\n",
    "# Extract only none nan values from the year 2022\n",
    "img_array = img_array[:,0:1701,:,:,:]\n",
    "img_array = img_array[[4,4,4,4,4],:,:,:,:] ## 4 refers to 2022\n",
    "labels = labels[:,0:1701]\n",
    "\n",
    "height_array_tmp = height_array_tmp[0:1701,:,:]\n",
    "height_array = np.full((5,1701,11,11), fill_value=np.nan)\n",
    "height_array[0,:,:,:] = height_array_tmp\n",
    "height_array[1,:,:,:] = height_array_tmp\n",
    "height_array[2,:,:,:] = height_array_tmp\n",
    "height_array[3,:,:,:] = height_array_tmp\n",
    "height_array[4,:,:,:] = height_array_tmp\n",
    "\n",
    "max_height = np.max(height_array_tmp)\n",
    "min_height = np.min(height_array_tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign labels as integers to different trees species"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As tensorflow prefers integers compared to strings as target values, we transform our labels array. As a first step, we create a new array that looks exactly like labels but is filled with zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Kommentar Caro:*\n",
    "Hier werden nur die eine Ahorn und die eine Birkenart codiert, die anderen beiden Arten der jeweiligen Gattungen fallen damit noch in die 'Other' Kategorie.\n",
    "\n",
    "Nochmal diskutieren/anpassen!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New array filled with 0s\n",
    "labels_int = np.zeros_like(labels)\n",
    "\n",
    "# Loop through each label\n",
    "for i in range(len(labels[1])):\n",
    "    \n",
    "    # Assign a 1 if it is a Rotbuche\n",
    "    if labels[1][i] == 'Rotbuche':\n",
    "        labels_int[:,i] = 1\n",
    "\n",
    "    # Assign a 2 if it is a Berg-Ahorn    \n",
    "    elif labels[1][i] == 'Berg-Ahorn':\n",
    "        labels_int[:,i] = 2\n",
    "\n",
    "    # Assign a 3 if it is a Haenge-Birke    \n",
    "    elif labels[1][i] == 'Haenge-Birke':\n",
    "        labels_int[:,i] = 3\n",
    "    \n",
    "# As the array is still of type \"obj\", we need to change it to \"int\"\n",
    "labels_int = labels_int.astype('int')\n",
    "\n",
    "# # Only use the classes that are really interesting for us\n",
    "# img_array = img_array[:,(labels_int[1] != 0),:,:,:]\n",
    "# labels_int = labels_int[:,(labels_int[1] != 0)] - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into a train, test and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create as many indices as there are trees (irrespective of years)\n",
    "ind = np.arange(0, img_array.shape[1], 1)\n",
    "\n",
    "# Split the indices into a train and temporary test set\n",
    "ind_train, ind_test_tmp, label_train, label_test_tmp = \\\n",
    "    train_test_split(ind, labels_int[1], train_size=0.8,\n",
    "                     stratify=labels_int[1], random_state=42)\n",
    "\n",
    "# Split the temporary test indices once again into a test and validation set\n",
    "ind_test, ind_validation, label_test, label_validation = \\\n",
    "    train_test_split(ind_test_tmp, label_test_tmp, train_size=0.5, \n",
    "                     stratify=label_test_tmp, random_state=42)\n",
    "\n",
    "# Extract images and labels for the train data set using the train indices\n",
    "# and reshape them so that there is once again only one dimension of images\n",
    "# irrespective of the year they are coming from\n",
    "img_train = img_array[:,ind_train,:,:,:].\\\n",
    "    reshape(labels_int.shape[0]*ind_train.shape[0],35,35,4)\n",
    "height_train = height_array[:,ind_train,:,:].\\\n",
    "    reshape(labels_int.shape[0]*ind_train.shape[0],11,11)\n",
    "label_train = labels_int[:,ind_train].\\\n",
    "    reshape(labels_int.shape[0]*ind_train.shape[0])\n",
    "\n",
    "# Extract images and labels for the test data set using the test indices\n",
    "# and reshape them so that there is once again only one dimension of images\n",
    "# irrespective of the year they are coming from\n",
    "img_test = img_array[:,ind_test,:,:,:].\\\n",
    "    reshape(labels_int.shape[0]*ind_test.shape[0],35,35,4)\n",
    "height_test = height_array[:,ind_test,:,:].\\\n",
    "    reshape(labels_int.shape[0]*ind_test.shape[0],11,11)\n",
    "label_test = labels_int[:,ind_test].\\\n",
    "    reshape(labels_int.shape[0]*ind_test.shape[0])\n",
    "\n",
    "# Extract images and labels for the validation data set using the validation\n",
    "# indices and reshape them so that there is once again only one dimension of\n",
    "# images irrespective of the year they are coming from\n",
    "img_validation = img_array[:,ind_validation,:,:,:].\\\n",
    "    reshape(labels_int.shape[0]*ind_validation.shape[0],35,35,4)\n",
    "height_validation = height_array[:,ind_validation,:,:].\\\n",
    "    reshape(labels_int.shape[0]*ind_validation.shape[0],11,11)    \n",
    "label_validation = labels_int[:,ind_validation].\\\n",
    "    reshape(labels_int.shape[0]*ind_validation.shape[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform data augmentation for a given set of images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To deal with the low sample size of the data set, we will first create new images, by augmenting the existing ones.\n",
    "\n",
    "We only perform flips and 90° rotations as other augmentations may interfere with vital information in the image - let's  be crazy and flip and rotate all images in all possible combinations (x12).\n",
    "\n",
    "We first create a function for this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that takes a dataset of images and augments each image\n",
    "# once in a certain way\n",
    "def augment_images(img_array):\n",
    "\n",
    "    # Predefine an array that will contain the augmented images\n",
    "    img_array_full = np.tile(img_array, (12,1,1,1,1))\n",
    "\n",
    "    # Loop through each image\n",
    "    for i in range(img_array.shape[0]):\n",
    "\n",
    "        # Augmentation number 0: Nothing\n",
    "        img_aug = img_array_full[0,i,:,:,:]\n",
    "        img_array_full[0,i,:,:,:] = img_aug\n",
    "\n",
    "        # Augmentation number 1: 90° rotation        \n",
    "        img_aug = tf.image.rot90(img_array[i], k=1).numpy()\n",
    "        img_array_full[1,i,:,:,:] = img_aug\n",
    "\n",
    "        # Augmentation number 2: 90° rotation + vertical flip\n",
    "        img_aug = tf.image.rot90(img_array[i], k=1).numpy()\n",
    "        img_aug = tf.image.flip_up_down(img_aug).numpy()\n",
    "        img_array_full[2,i,:,:,:] = img_aug\n",
    "\n",
    "        # Augmentation number 3: 90° rotation + horizontal flip\n",
    "        img_aug = tf.image.rot90(img_array[i], k=1).numpy()\n",
    "        img_aug = tf.image.flip_left_right(img_aug).numpy()\n",
    "        img_array_full[3,i,:,:,:] = img_aug\n",
    "\n",
    "        # Augmentation number 4: 90° rotation + vertical flip +\n",
    "        # horizontal flip\n",
    "        img_aug = tf.image.rot90(img_array[i], k=1).numpy()\n",
    "        img_aug = tf.image.flip_up_down(img_aug).numpy()\n",
    "        img_aug = tf.image.flip_left_right(img_aug).numpy()\n",
    "        img_array_full[4,i,:,:,:] = img_aug\n",
    "\n",
    "        # Augmentation number 5: 270° rotation\n",
    "        img_aug = tf.image.rot90(img_array[i], k=3).numpy()\n",
    "        img_array_full[5,i,:,:,:] = img_aug\n",
    "\n",
    "        # Augmentation number 6: 270° rotation + vertical flip\n",
    "        img_aug = tf.image.rot90(img_array[i], k=3).numpy()\n",
    "        img_aug = tf.image.flip_up_down(img_aug).numpy()\n",
    "        img_array_full[6,i,:,:,:] = img_aug\n",
    "\n",
    "        # Augmentation number 7: 90° rotation + horizontal flip\n",
    "        img_aug = tf.image.rot90(img_array[i], k=3).numpy()\n",
    "        img_aug = tf.image.flip_left_right(img_aug).numpy()\n",
    "        img_array_full[7,i,:,:,:] = img_aug\n",
    "\n",
    "        # Augmentation number 8: 270° rotation + vertical flip +\n",
    "        # horizontal flip\n",
    "        img_aug = tf.image.rot90(img_array[i], k=3).numpy()\n",
    "        img_aug = tf.image.flip_up_down(img_aug).numpy()\n",
    "        img_aug = tf.image.flip_left_right(img_aug).numpy()\n",
    "        img_array_full[8,i,:,:,:] = img_aug\n",
    "\n",
    "        # Augmentation number 9: vertical flip + horizontal flip\n",
    "        img_aug = tf.image.flip_up_down(img_array[i]).numpy()\n",
    "        img_aug = tf.image.flip_left_right(img_aug).numpy()\n",
    "        img_array_full[9,i,:,:,:] = img_aug\n",
    "\n",
    "        # Augmentation number 10: vertical flip\n",
    "        img_aug = tf.image.flip_up_down(img_array[i]).numpy()\n",
    "        img_array_full[10,i,:,:,:] = img_aug\n",
    "\n",
    "        # Augmentation number 11: horizontal flip\n",
    "        img_aug = tf.image.flip_left_right(img_array[i]).numpy()\n",
    "        img_array_full[11,i,:,:,:] = img_aug\n",
    "\n",
    "        # Report progress\n",
    "        if (i%1000 == 0) & (i != 0):\n",
    "            print(' - ' + str(round(100*i/img_array.shape[0])) + \n",
    "            '% of all images have been augmented.')\n",
    "        elif (i%100 == 0) & (i != 0):\n",
    "            print('.', end='')\n",
    "        \n",
    "    # Return the augmented dataset\n",
    "    return img_array_full\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let´s use the function for augmentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augment spectral training images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-11 15:04:11.171384: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2023-08-11 15:04:11.171475: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2023-08-11 15:04:11.171489: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2023-08-11 15:04:11.172793: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-08-11 15:04:11.175516: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "......... - 15% of all images have been augmented.\n",
      "......... - 29% of all images have been augmented.\n",
      "......... - 44% of all images have been augmented.\n",
      "......... - 59% of all images have been augmented.\n",
      "......... - 74% of all images have been augmented.\n",
      "......... - 88% of all images have been augmented.\n",
      ".......\n",
      "\n",
      "Augment vegetation height training images\n",
      "......... - 15% of all images have been augmented.\n",
      "......... - 29% of all images have been augmented.\n",
      "......... - 44% of all images have been augmented.\n",
      "......... - 59% of all images have been augmented.\n",
      "......... - 74% of all images have been augmented.\n",
      "......... - 88% of all images have been augmented.\n",
      ".......\n",
      "\n",
      "\"Augment\" labels\n"
     ]
    }
   ],
   "source": [
    "# Augment data\n",
    "print('Augment spectral training images')\n",
    "img_train_full = augment_images(img_train)\n",
    "print('\\n\\nAugment vegetation height training images')\n",
    "height_train_full = np.squeeze(augment_images(height_train[:,:,:,np.newaxis]))\n",
    "print('\\n\\n\"Augment\" labels')\n",
    "label_train_full = np.tile(label_train, (12,1))\n",
    "\n",
    "# Reshape augmented data\n",
    "img_train = np.reshape(img_train_full, (-1,35,35,4))\n",
    "height_train = np.reshape(height_train_full, (-1,11,11))\n",
    "label_train = np.reshape(label_train_full, (-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(label_train.shape[0]/12)\n",
    "\n",
    "# print(label_train[ 0*6800+1111])\n",
    "# print(label_train[ 1*6800+1111])\n",
    "# print(label_train[ 2*6800+1111])\n",
    "# print(label_train[ 3*6800+1111])\n",
    "# print(label_train[ 4*6800+1111])\n",
    "# print(label_train[ 5*6800+1111])\n",
    "# print(label_train[ 6*6800+1111])\n",
    "# print(label_train[ 7*6800+1111])\n",
    "# print(label_train[ 8*6800+1111])\n",
    "# print(label_train[ 9*6800+1111])\n",
    "# print(label_train[10*6800+1111])\n",
    "# print(label_train[11*6800+1111])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let´s check the shape of our train-datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81600, 35, 35, 4)\n",
      "(81600, 11, 11)\n",
      "(81600,)\n"
     ]
    }
   ],
   "source": [
    "print(img_train.shape)\n",
    "print(height_train.shape)\n",
    "print(label_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deal with class imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have highly imbalanced data with 55% beech trees dominating the dataset, we explored different approaches to deal with imbalanced data. We tested and compared\n",
    "- weighted classes\n",
    "- oversampling\n",
    "- undersampling\n",
    "\n",
    "but found that **oversampling** worked best for our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will randomly draw from the pool of original and augemented images to increase the sample sizes of the minorty classes, until the same size as for the majority class is reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the frequency of each class in the data\n",
    "_, n_all = np.unique(label_train, return_counts=True)\n",
    "\n",
    "# Determine the class with the most data\n",
    "n_max = np.max(n_all)\n",
    "\n",
    "# Generate a new array that contains the uosampled image results\n",
    "img_os = img_train.copy()\n",
    "\n",
    "# Generate a new array that contains the uosampled image results\n",
    "height_os = height_train.copy()\n",
    "\n",
    "# Generate a new array that contains the uosampled label results\n",
    "label_os = label_train.copy()\n",
    "\n",
    "# Loop through all class categories\n",
    "for i in range(len(n_all)):\n",
    "\n",
    "    # Extract the frequency of this class\n",
    "    n_class = n_all[i]\n",
    "\n",
    "    # Execute this code if this is not the class with the highest\n",
    "    # frequency\n",
    "    if (n_class != n_max):\n",
    "\n",
    "        # Extract only images of this class\n",
    "        img_class = img_train[label_train == i]\n",
    "\n",
    "        # Extract only heights of this class\n",
    "        height_class = height_train[label_train == i]        \n",
    "\n",
    "        # Extract only labels of this class\n",
    "        label_class = label_train[label_train == i]\n",
    "\n",
    "        # Generate as many random integers as there are in the class\n",
    "        # category with the highest frequency minus the number of already\n",
    "        # existing images for this class category\n",
    "        rand_ind = np.random.randint(0, img_class.shape[0]-1,\n",
    "                                     n_max - n_class)\n",
    "\n",
    "        # Draw random images from the existing images\n",
    "        img_rand = img_class[rand_ind,:,:,:]\n",
    "\n",
    "        # Draw random heights from the existing images\n",
    "        height_rand = height_class[rand_ind,:,:]\n",
    "\n",
    "        # Draw the very same random labels\n",
    "        label_rand = label_class[rand_ind]\n",
    "\n",
    "        # Append images to the image array\n",
    "        img_os = np.append(img_os, img_rand, axis=0)\n",
    "\n",
    "        # Append heights to the image array\n",
    "        height_os = np.append(height_os, height_rand, axis=0)     \n",
    "\n",
    "        # Append the very same random labels to the labels array\n",
    "        label_os = np.append(label_os, label_rand, axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(181440,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_os.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding for the lables\n",
    "label_os_ohe = tf.keras.utils.to_categorical(label_os)\n",
    "label_test_ohe = tf.keras.utils.to_categorical(label_test)\n",
    "label_validation_ohe = tf.keras.utils.to_categorical(label_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper parameter search for a CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the spectral information is the main part of our model, we will optimize the hyper parameters for this. We will use hyperparameter tuning to find a good kernel_initializer, the best learning rate as well as the best filter and dropuout rates.\n",
    "\n",
    "We are the using Hyperband tuning algorithm, which uses adaptive resource allocation and early-stopping to quickly converge on a high-performing model.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install keras-tuner\n",
    "from kerastuner import Hyperband\n",
    "from kerastuner.engine.hyperparameters import HyperParameters\n",
    "\n",
    "# Create a callback to stop training early after reaching a certain value for the validation loss.\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have identified a good CNN structure, so we will use this here. \n",
    "As the Keras Tuner cannot work with Pooling layers, so they are not included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the  model function\n",
    "\n",
    "def model_builder(hp):\n",
    "    model = tf.keras.models.Sequential()\n",
    "\n",
    "    model.add(tf.keras.layers.InputLayer(input_shape=[35,35,4]))\n",
    "    model.add(tf.keras.layers.Rescaling(1/((2**16)-1)))\n",
    "\n",
    "\n",
    "    hp_filters1 = hp.Choice('filters1', values=[16, 32, 64]) #32 is best\n",
    "    hp_dropout1 = hp.Choice('dropout1', values = [0.0, 0.2, 0.4])\n",
    "    hp_initializer1 = hp.Choice('initializer1', values = ['uniform', 'he_normal','random_normal', 'he_uniform'])\n",
    "    model.add(tf.keras.layers.Conv2D(filters=hp_filters1, kernel_size=[3, 3], strides=2, kernel_initializer= hp_initializer1, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(hp_dropout1))\n",
    "\n",
    "    hp_filters2 = hp.Choice('filters2', values=[64, 128, 256]) #128 is best\n",
    "    hp_dropout2 = hp.Choice('dropout2', values = [0.3, 0.4, 0.5])\n",
    "    model.add(tf.keras.layers.Conv2D(filters=hp_filters2, kernel_size=[3, 3], strides=2, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(hp_dropout2))\n",
    "\n",
    "    hp_filters3 = hp.Choice('filters3', values=[64, 128, 256]) #128 is best\n",
    "    hp_dropout3 = hp.Choice('dropout3', values = [ 0.0, 0.2, 0.4])\n",
    "    model.add(tf.keras.layers.Conv2D(filters=hp_filters3, kernel_size=[3,3], activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(hp_dropout3))\n",
    "\n",
    "\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "    hp_filters4 = hp.Choice('filters4', values=[16, 32, 64])\n",
    "    hp_dropout4 = hp.Choice('dropout4', values = [ 0.0, 0.2, 0.4])\n",
    "    model.add(tf.keras.layers.Dense(units=hp_filters4, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(hp_dropout4))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(units=4, activation='softmax')) \n",
    "\n",
    "\n",
    "    # Tune the learning rate for the optimizer\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[0.01, 0.001, 0.0001])\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "# Hyperband determines the number of models to train in a bracket by \n",
    "# computing 1 + log factor(max_epochs) and rounding it up to the nearest integer.\n",
    "\n",
    "tuner = kt.Hyperband(model_builder,\n",
    "                    objective='val_accuracy',\n",
    "                    max_epochs=70,\n",
    "                    factor=3,\n",
    "                    directory='../data',\n",
    "                    project_name='CNN_test_initializer_v1') #always change from run to run, otherwise triggered exit\n",
    "\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "/Users/carolinmundinger/.pyenv/versions/3.11.3/lib/python3.11/site-packages/keras/src/backend.py:5714: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n",
      "2023-08-11 15:16:26.541785: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-11 15:17:13.750276: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "2023-08-11 15:19:45.373469: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-11 15:20:39.422292: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "2023-08-11 15:23:28.043294: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#tuner.search(img_train, label_train, epochs=70, validation_split=0.2, callbacks=[stop_early]) #for original train data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m tuner\u001b[39m.\u001b[39;49msearch(img_os, label_os, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m, callbacks\u001b[39m=\u001b[39;49m[stop_early], verbose \u001b[39m=\u001b[39;49m \u001b[39m0\u001b[39;49m) \u001b[39m#for oversampled ata \u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m# get the optimal hyperparameters\u001b[39;00m\n\u001b[1;32m      5\u001b[0m best_hps\u001b[39m=\u001b[39mtuner\u001b[39m.\u001b[39mget_best_hyperparameters(num_trials\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/keras_tuner/engine/base_tuner.py:230\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_trial_begin(trial)\n\u001b[0;32m--> 230\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_run_and_update_trial(trial, \u001b[39m*\u001b[39;49mfit_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_kwargs)\n\u001b[1;32m    231\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_trial_end(trial)\n\u001b[1;32m    232\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_search_end()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/keras_tuner/engine/base_tuner.py:270\u001b[0m, in \u001b[0;36mBaseTuner._try_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_run_and_update_trial\u001b[39m(\u001b[39mself\u001b[39m, trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs):\n\u001b[1;32m    269\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 270\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_and_update_trial(trial, \u001b[39m*\u001b[39;49mfit_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_kwargs)\n\u001b[1;32m    271\u001b[0m         trial\u001b[39m.\u001b[39mstatus \u001b[39m=\u001b[39m trial_module\u001b[39m.\u001b[39mTrialStatus\u001b[39m.\u001b[39mCOMPLETED\n\u001b[1;32m    272\u001b[0m         \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/keras_tuner/engine/base_tuner.py:235\u001b[0m, in \u001b[0;36mBaseTuner._run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_and_update_trial\u001b[39m(\u001b[39mself\u001b[39m, trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs):\n\u001b[0;32m--> 235\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_trial(trial, \u001b[39m*\u001b[39;49mfit_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_kwargs)\n\u001b[1;32m    236\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mget_trial(trial\u001b[39m.\u001b[39mtrial_id)\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mexists(\n\u001b[1;32m    237\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mobjective\u001b[39m.\u001b[39mname\n\u001b[1;32m    238\u001b[0m     ):\n\u001b[1;32m    239\u001b[0m         \u001b[39m# The oracle is updated by calling `self.oracle.update_trial()` in\u001b[39;00m\n\u001b[1;32m    240\u001b[0m         \u001b[39m# `Tuner.run_trial()`. For backward compatibility, we support this\u001b[39;00m\n\u001b[1;32m    241\u001b[0m         \u001b[39m# use case. No further action needed in this case.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    243\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThe use case of calling \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    244\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m`self.oracle.update_trial(trial_id, metrics)` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    250\u001b[0m             stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[1;32m    251\u001b[0m         )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/keras_tuner/tuners/hyperband.py:425\u001b[0m, in \u001b[0;36mHyperband.run_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    423\u001b[0m     fit_kwargs[\u001b[39m\"\u001b[39m\u001b[39mepochs\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m hp\u001b[39m.\u001b[39mvalues[\u001b[39m\"\u001b[39m\u001b[39mtuner/epochs\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    424\u001b[0m     fit_kwargs[\u001b[39m\"\u001b[39m\u001b[39minitial_epoch\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m hp\u001b[39m.\u001b[39mvalues[\u001b[39m\"\u001b[39m\u001b[39mtuner/initial_epoch\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m--> 425\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mrun_trial(trial, \u001b[39m*\u001b[39;49mfit_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_kwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/keras_tuner/engine/tuner.py:287\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(model_checkpoint)\n\u001b[1;32m    286\u001b[0m     copied_kwargs[\u001b[39m\"\u001b[39m\u001b[39mcallbacks\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m callbacks\n\u001b[0;32m--> 287\u001b[0m     obj_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build_and_fit_model(trial, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcopied_kwargs)\n\u001b[1;32m    289\u001b[0m     histories\u001b[39m.\u001b[39mappend(obj_value)\n\u001b[1;32m    290\u001b[0m \u001b[39mreturn\u001b[39;00m histories\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/keras_tuner/engine/tuner.py:214\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m hp \u001b[39m=\u001b[39m trial\u001b[39m.\u001b[39mhyperparameters\n\u001b[1;32m    213\u001b[0m model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_build(hp)\n\u001b[0;32m--> 214\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhypermodel\u001b[39m.\u001b[39;49mfit(hp, model, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    215\u001b[0m tuner_utils\u001b[39m.\u001b[39mvalidate_trial_results(\n\u001b[1;32m    216\u001b[0m     results, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mobjective, \u001b[39m\"\u001b[39m\u001b[39mHyperModel.fit()\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    217\u001b[0m )\n\u001b[1;32m    218\u001b[0m \u001b[39mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/keras_tuner/engine/hypermodel.py:144\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, hp, model, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    121\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Train the model.\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \n\u001b[1;32m    123\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[39m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 144\u001b[0m     \u001b[39mreturn\u001b[39;00m model\u001b[39m.\u001b[39;49mfit(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1743\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function(\u001b[39m*\u001b[39;49margs))\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    197\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    198\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[1;32m    199\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[1;32m    200\u001b[0m     )\n\u001b[1;32m    201\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\u001b[39mself\u001b[39m, \u001b[39mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m   1458\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1459\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[1;32m   1460\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[1;32m   1461\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m   1462\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1463\u001b[0m   )\n\u001b[1;32m   1464\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#tuner.search(img_train, label_train, epochs=70, validation_split=0.2, callbacks=[stop_early]) #for original train data\n",
    "tuner.search(img_os, label_os, epochs=10, validation_split=0.2, callbacks=[stop_early], verbose = 0) #for oversampled ata \n",
    "\n",
    "# get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling Ensemble Model\n",
    "\n",
    "We will create en ensemble model, that combines different models for different parts of the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Convolutional neural network for the spectral data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_spec\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 35, 35, 4)]       0         \n",
      "                                                                 \n",
      " lambda (Lambda)             (None, 35, 35, 4)         0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 33, 33, 32)        1184      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 11, 11, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 11, 11, 32)        0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 9, 9, 64)          18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 3, 3, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 3, 3, 64)          0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 1, 1, 128)         73856     \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 1, 1, 128)         0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 128)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 93536 (365.38 KB)\n",
      "Trainable params: 93536 (365.38 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create model structure\n",
    "input_spec = tf.keras.layers.Input(shape=(35,35,4))\n",
    "scale_spec = tf.keras.layers.Lambda(lambda x: x/((2**16)-1), input_shape=(35,35,4))(input_spec)\n",
    "\n",
    "conv1_spec = tf.keras.layers.Conv2D(filters=32, kernel_size=[3,3], activation='relu')(scale_spec)\n",
    "pool1_spec = tf.keras.layers.MaxPooling2D(pool_size=[3,3])(conv1_spec)\n",
    "drop1_spec = tf.keras.layers.Dropout(0.2)(pool1_spec)\n",
    "\n",
    "conv2_spec = tf.keras.layers.Conv2D(filters=64, kernel_size=[3,3], activation='relu')(drop1_spec)\n",
    "pool2_spec = tf.keras.layers.MaxPooling2D(pool_size=[3,3])(conv2_spec)\n",
    "drop2_spec = tf.keras.layers.Dropout(0.4)(pool2_spec)\n",
    "\n",
    "conv3_spec = tf.keras.layers.Conv2D(filters=128, kernel_size=[3,3], activation='relu')(drop2_spec)\n",
    "drop3_spec = tf.keras.layers.Dropout(0.2)(conv3_spec)\n",
    "\n",
    "flat1_spec = tf.keras.layers.Flatten()(drop3_spec)\n",
    "\n",
    "# dens1_spec = tf.keras.layers.Dense(units=32, activation='relu')(flat1_spec)\n",
    "# drop4_spec = tf.keras.layers.Dropout(0.25)(dens1_spec)\n",
    "\n",
    "# output_spec = tf.keras.layers.Dense(units=3, activation='softmax')(drop4_spec)\n",
    "\n",
    "model_spec = tf.keras.Model(input_spec, flat1_spec, name=\"model_spec\")\n",
    "\n",
    "model_spec.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Convolutional neural network for the vegetation height data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_height\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 11, 11, 1)]       0         \n",
      "                                                                 \n",
      " lambda_1 (Lambda)           (None, 11, 11, 1)         0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 9, 9, 32)          320       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 3, 3, 32)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 3, 3, 32)          0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 1, 1, 64)          18496     \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 1, 1, 64)          0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 64)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18816 (73.50 KB)\n",
      "Trainable params: 18816 (73.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define  the convolutional neural network for the vegetation height data\n",
    "\n",
    "input_height = tf.keras.layers.Input(shape=(11,11,1))\n",
    "scale_height = tf.keras.layers.Lambda(lambda x: ((x-min_height)/(max_height-min_height)), input_shape=(11,11,1))(input_height)\n",
    "\n",
    "conv1_height = tf.keras.layers.Conv2D(filters=32, kernel_size=[3,3], activation='relu')(scale_height)\n",
    "pool1_height = tf.keras.layers.MaxPooling2D(pool_size=[3,3])(conv1_height)\n",
    "drop1_height = tf.keras.layers.Dropout(0.4)(pool1_height)\n",
    "\n",
    "conv2_height = tf.keras.layers.Conv2D(filters=64, kernel_size=[3,3], activation='relu')(drop1_height)\n",
    "drop2_height = tf.keras.layers.Dropout(0.2)(conv2_height)\n",
    "\n",
    "flat1_height = tf.keras.layers.Flatten()(drop2_height)\n",
    "\n",
    "# dens1_height = tf.keras.layers.Dense(units=32, activation='relu')(flat1_height)\n",
    "# drop4_height = tf.keras.layers.Dropout(0.25)(dens1_height)\n",
    "\n",
    "# output_height = tf.keras.layers.Dense(units=3, activation='softmax')(drop4_height)\n",
    "\n",
    "model_height = tf.keras.Model(input_height, flat1_height, name=\"model_height\")\n",
    "\n",
    "model_height.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine both models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_speight\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 35, 35, 4)]          0         []                            \n",
      "                                                                                                  \n",
      " lambda (Lambda)             (None, 35, 35, 4)            0         ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (None, 33, 33, 32)           1184      ['lambda[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2  (None, 11, 11, 32)           0         ['conv2d_3[0][0]']            \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)        [(None, 11, 11, 1)]          0         []                            \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)         (None, 11, 11, 32)           0         ['max_pooling2d[0][0]']       \n",
      "                                                                                                  \n",
      " lambda_1 (Lambda)           (None, 11, 11, 1)            0         ['input_3[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)           (None, 9, 9, 64)             18496     ['dropout_4[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)           (None, 9, 9, 32)             320       ['lambda_1[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPoolin  (None, 3, 3, 64)             0         ['conv2d_4[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPoolin  (None, 3, 3, 32)             0         ['conv2d_6[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)         (None, 3, 3, 64)             0         ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)         (None, 3, 3, 32)             0         ['max_pooling2d_2[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)           (None, 1, 1, 128)            73856     ['dropout_5[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)           (None, 1, 1, 64)             18496     ['dropout_7[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)         (None, 1, 1, 128)            0         ['conv2d_5[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)         (None, 1, 1, 64)             0         ['conv2d_7[0][0]']            \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)         (None, 128)                  0         ['dropout_6[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)         (None, 64)                   0         ['dropout_8[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 192)                  0         ['flatten_1[0][0]',           \n",
      "                                                                     'flatten_2[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 32)                   6176      ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)         (None, 32)                   0         ['dense_2[0][0]']             \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 16)                   528       ['dropout_9[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)        (None, 16)                   0         ['dense_3[0][0]']             \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 4)                    68        ['dropout_10[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 119124 (465.33 KB)\n",
      "Trainable params: 119124 (465.33 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Combine the different convolutional neural networks to one inference\n",
    "\n",
    "# Concatenate both models from before\n",
    "cross_speight = tf.keras.layers.concatenate([flat1_spec, flat1_height]) \n",
    "\n",
    "# Add more layers:\n",
    "dens1_speight = tf.keras.layers.Dense(units=32, activation='relu')(cross_speight)\n",
    "drop1_speight = tf.keras.layers.Dropout(.4)(dens1_speight)\n",
    "\n",
    "dens2_speight = tf.keras.layers.Dense(units=16, activation='relu')(drop1_speight)\n",
    "drop2_speight = tf.keras.layers.Dropout(.2)(dens2_speight)\n",
    "\n",
    "# For the last output layer:\n",
    "# units set to 4 because we have 4 classes\n",
    "# softmax is commonly used for multi-class single-label classificiation\n",
    "output_speight = tf.keras.layers.Dense(units=4, activation='softmax')(drop2_speight)\n",
    "\n",
    "model_speight = tf.keras.models.Model(inputs=[input_spec, input_height], outputs=output_speight, name=\"model_speight\")\n",
    "\n",
    "model_speight.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_speight.compile(optimizer=tf.keras.optimizers.RMSprop(),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing = 0.1),\n",
    "              metrics=['categorical_accuracy'])\n",
    "\n",
    "history_speight = model_speight.fit(x=[img_os, height_os], y=label_os_ohe, epochs=25, validation_data=([img_test, height_test], label_test_ohe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss function\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10,6))\n",
    "ax.plot(history_speight.history['loss'], 'r', label='train')\n",
    "ax.plot(history_speight.history['val_loss'], 'b' ,label='val')\n",
    "ax.set_xlabel(r'Epoch', fontsize=20)\n",
    "ax.set_ylabel(r'Loss', fontsize=20)\n",
    "ax.legend()\n",
    "ax.tick_params(labelsize=20)\n",
    "\n",
    "# Plot the accuracy\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10,6))\n",
    "ax.plot(history_speight.history[\"categorical_accuracy\"], 'r', label='train')\n",
    "ax.plot(history_speight.history['val_categorical_accuracy'], 'b' ,label='val')\n",
    "ax.set_xlabel(r'Epoch', fontsize=20)\n",
    "ax.set_ylabel(r'Accuracy', fontsize=20)\n",
    "ax.legend()\n",
    "ax.tick_params(labelsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results of the ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the performance of the model\n",
    "model_speight.evaluate(x=[img_validation, height_validation], y=label_validation_ohe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create prediction for the validation dataset and evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict from fitted model\n",
    "predictions = model_speight.predict([img_validation, height_validation], verbose=0)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Calculate class percentages\n",
    "class_percentages = np.unique(label_validation, return_counts=True)[1]/len(label_validation) * 100\n",
    "\n",
    "# Calculate predicted class percentages\n",
    "pred_class_percentages = np.unique(predicted_labels, return_counts=True)[1]/len(predicted_labels) * 100\n",
    "\n",
    "# Define class names\n",
    "CLASS_NAMES = ['Other', 'Rotbuche','Ahorn','Birke'] # Stimmt die Reihenfolge, Alex?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let´s compare the actural proportions of each class in the original data versus the predicted proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Actual proportions')\n",
    "# Look at class percentages\n",
    "for class_name, percentage in zip(CLASS_NAMES, class_percentages):\n",
    "    print(f'{class_name}: {percentage:.2f}%')\n",
    "\n",
    "print('\\n')\n",
    "print('Predicted proportions')\n",
    "# Look at predicted class percentages\n",
    "for class_name, percentage in zip(CLASS_NAMES, pred_class_percentages):\n",
    "    print(f'{class_name}: {percentage:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Create matrix\n",
    "confusion = confusion_matrix(np.reshape(label_validation, (5,-1))[1,:], np.reshape(predicted_labels, (5,-1))[1,:])\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=CLASS_NAMES, yticklabels=CLASS_NAMES)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "report = classification_report(label_validation, predicted_labels, target_names=CLASS_NAMES)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How well does the trained model work on other datasets?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we test how well our fitted model (that was trained on the data from 2022) can be transferred to another data set.\n",
    "As an example, we test our fitted model for the data from 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the data file\n",
    "data_path = '../images/box_images/baseline/model_images.npz'\n",
    "\n",
    "# Load the image array containing all box images in a 4D array and their\n",
    "# labels\n",
    "with np.load(data_path, allow_pickle=True) as data:\n",
    "    img_array = data[\"img_array\"]\n",
    "    labels = data[\"labels\"]\n",
    "\n",
    "# Extract only none nan values from the year 2018 \n",
    "img_array = img_array[:,0:1701,:,:,:]\n",
    "img_array = np.reshape(img_array[[2,2,2,2,2],:,:,:,:], (-1,35,35,4)) ## 2 refers to 2018\n",
    "height_array = np.reshape(height_array, (-1,11,11))\n",
    "label_array = np.reshape(labels[:,0:1701], (-1))\n",
    "\n",
    "# As tensorflow prefers integers compared to strings as target values, we \n",
    "# transform our labels array. As a first step, create a new array that\n",
    "# looks exactly like labels but is filled with zeros\n",
    "labels_int = np.zeros_like(label_array)\n",
    "\n",
    "# Loop through each label\n",
    "for i in range(len(label_array)):\n",
    "    \n",
    "    # Assign a 1 if it is a Rotbuche\n",
    "    if label_array[i] == 'Rotbuche':\n",
    "        labels_int[i] = 1\n",
    "\n",
    "    # Assign a 2 if it is a Berg-Ahorn    \n",
    "    elif label_array[i] == 'Berg-Ahorn':\n",
    "        labels_int[i] = 2\n",
    "\n",
    "    # Assign a 3 if it is a Haenge-Birke    \n",
    "    elif label_array[i] == 'Haenge-Birke':\n",
    "        labels_int[i] = 3\n",
    "    \n",
    "# As the array is still of type \"obj\", we need to change it to \"int\"\n",
    "labels_int = labels_int.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(labels_int, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict from fitted model\n",
    "predictions = model_speight.predict([img_array, height_array], verbose=0)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Calculate class percentages\n",
    "class_percentages = np.unique(labels_int, return_counts=True)[1]/len(labels_int) * 100\n",
    "\n",
    "# Calculate predicted class percentages\n",
    "pred_class_percentages = np.unique(predicted_labels, return_counts=True)[1]/len(predicted_labels) * 100\n",
    "\n",
    "# Define class names\n",
    "CLASS_NAMES = ['Other', 'Rotbuche','Ahorn','Birke'] # Stimmt die Reihenfolge, Alex?\n",
    "\n",
    "print('Actual proportions')\n",
    "# Look at class percentages\n",
    "for class_name, percentage in zip(CLASS_NAMES, class_percentages):\n",
    "    print(f'{class_name}: {percentage:.2f}%')\n",
    "\n",
    "print('\\n')\n",
    "print('Predicted proportions')\n",
    "# Look at predicted class percentages\n",
    "for class_name, percentage in zip(CLASS_NAMES, pred_class_percentages):\n",
    "    print(f'{class_name}: {percentage:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(labels_int == predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Create matrix\n",
    "confusion = confusion_matrix(np.reshape(labels_int, (5,-1))[1,:], np.reshape(predicted_labels, (5,-1))[1,:])\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=CLASS_NAMES, yticklabels=CLASS_NAMES)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
