{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 Data Preprocessing\n",
    "In this Notebook we will preprocess the data we generated earlier. We will:\n",
    "- Categorize trees into the 4 classes\n",
    "- Normalize the image data\n",
    "- Split the data into training, validation and test sets\n",
    "- Apply data augmentation techniques\n",
    "- Perform oversampling\n",
    "- One-hot encode the labels\n",
    "\n",
    "__Note:__ For demonstration purposes we will only process the TDOP data in this Notebook. Processing vegetation height and other data in raster format works the same way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing needed libraries & packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading, relabeling the data and encoding the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the data file\n",
    "data_path = './data/TDOP.npz'\n",
    "\n",
    "# Load the image array containing all box images in a 4D array and their\n",
    "# labels\n",
    "with np.load(data_path, allow_pickle=True) as data:\n",
    "    img_array = data[\"trees\"]\n",
    "    labels = data[\"labels\"]\n",
    "\n",
    "img_array = img_array[[4,4,4,4,4],:,:,:,:] # after loading the data we only the take the most current picture information\n",
    "labels = labels[[4,4,4,4,4],:].astype(\"object\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow prefers integers as target values, therefore we have to transform our labels.\n",
    " \n",
    "As a first step, create a new array filled with zeros and in the same shape as the \"labels\". \n",
    "The we replace all zeros with integers as in the position where one of the 3 tree species of interest are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_int = np.zeros_like(labels)\n",
    "\n",
    "# Loop through each label\n",
    "for i in range(len(labels[1])):\n",
    "    \n",
    "    # Assign a 1 if it is a Rotbuche\n",
    "    if labels[1][i] == 'Rotbuche':\n",
    "        labels_int[:,i] = 1\n",
    "\n",
    "    # Assign a 2 if it is Ahorn    \n",
    "    elif labels[1][i] == 'Berg-Ahorn' or labels[1][i] == 'Feld-Ahorn':\n",
    "        labels_int[:,i] = 2\n",
    "\n",
    "    # Assign a 3 if it is a Birke    \n",
    "    elif labels[1][i] == 'Haenge-Birke' or labels[1][i] == 'Moor-Birke':\n",
    "        labels_int[:,i] = 3\n",
    "    \n",
    "# The array is still of type \"obj\", we need to change it to \"int\"\n",
    "labels_int = labels_int.astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will do the one-hot encoding later just before saving the preprocessed data for the model. What we will do now is normalizing our 16-bit image data to the 0 - 1 range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_array = tf.keras.utils.normalize(img_array, axis=-1, order=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 1703, 35, 35, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting the data into training, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking how many channels the image data has, 4 for standard RGB+IR TDOP images, 3 would be RGB only\n",
    "nr_channels = img_array.shape[-1]\n",
    "\n",
    "# Reshape the arrays \n",
    "reshaped_img = img_array.reshape(-1, 35, 35, nr_channels)\n",
    "reshaped_labels = labels_int.reshape(-1)\n",
    "\n",
    "# Setting the split ratios\n",
    "train_size = 0.8\n",
    "val_size = 0.1\n",
    "test_size =  val_size / (1 - train_size)\n",
    "# Generate indices for splitting\n",
    "idx_train, idx_temp, labels_train, labels_temp = train_test_split(np.arange(len(reshaped_img)), reshaped_labels, train_size=train_size, stratify=reshaped_labels)\n",
    "idx_val, idx_test, labels_val, labels_test = train_test_split(idx_temp, labels_temp, test_size=test_size, stratify=labels_temp)\n",
    "\n",
    "# Split the data and reshape back\n",
    "img_train = reshaped_img[idx_train]\n",
    "img_val = reshaped_img[idx_val]\n",
    "img_test = reshaped_img[idx_test]\n",
    "\n",
    "# Reshape labels arrays\n",
    "labels_train = labels_train.reshape(-1)\n",
    "labels_val = labels_val.reshape(-1)\n",
    "labels_test = labels_test.reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again lets see how the different sets look like now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6812, 35, 35, 4)\n",
      "(6812,)\n"
     ]
    }
   ],
   "source": [
    "print(img_train.shape)\n",
    "print(labels_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that takes a dataset of images and augments each image\n",
    "# once in a certain way\n",
    "def augment_images(img_array):\n",
    "\n",
    "    # Predefine an array that will contain the augmented images\n",
    "    img_array_full = np.tile(img_array, (12,1,1,1,1))\n",
    "\n",
    "    # Loop through each image\n",
    "    for i in range(img_array.shape[0]):\n",
    "\n",
    "        # Augmentation number 0: Nothing\n",
    "        img_aug = img_array_full[0,i,:,:,:]\n",
    "        img_array_full[0,i,:,:,:] = img_aug\n",
    "\n",
    "        # Augmentation number 1: 90° rotation        \n",
    "        img_aug = tf.image.rot90(img_array[i], k=1).numpy()\n",
    "        img_array_full[1,i,:,:,:] = img_aug\n",
    "\n",
    "        # Augmentation number 2: 90° rotation + vertical flip\n",
    "        img_aug = tf.image.rot90(img_array[i], k=1).numpy()\n",
    "        img_aug = tf.image.flip_up_down(img_aug).numpy()\n",
    "        img_array_full[2,i,:,:,:] = img_aug\n",
    "\n",
    "        # Augmentation number 3: 90° rotation + horizontal flip\n",
    "        img_aug = tf.image.rot90(img_array[i], k=1).numpy()\n",
    "        img_aug = tf.image.flip_left_right(img_aug).numpy()\n",
    "        img_array_full[3,i,:,:,:] = img_aug\n",
    "\n",
    "        # Augmentation number 4: 90° rotation + vertical flip +\n",
    "        # horizontal flip\n",
    "        img_aug = tf.image.rot90(img_array[i], k=1).numpy()\n",
    "        img_aug = tf.image.flip_up_down(img_aug).numpy()\n",
    "        img_aug = tf.image.flip_left_right(img_aug).numpy()\n",
    "        img_array_full[4,i,:,:,:] = img_aug\n",
    "\n",
    "        # Augmentation number 5: 270° rotation\n",
    "        img_aug = tf.image.rot90(img_array[i], k=3).numpy()\n",
    "        img_array_full[5,i,:,:,:] = img_aug\n",
    "\n",
    "        # Augmentation number 6: 270° rotation + vertical flip\n",
    "        img_aug = tf.image.rot90(img_array[i], k=3).numpy()\n",
    "        img_aug = tf.image.flip_up_down(img_aug).numpy()\n",
    "        img_array_full[6,i,:,:,:] = img_aug\n",
    "\n",
    "        # Augmentation number 7: 90° rotation + horizontal flip\n",
    "        img_aug = tf.image.rot90(img_array[i], k=3).numpy()\n",
    "        img_aug = tf.image.flip_left_right(img_aug).numpy()\n",
    "        img_array_full[7,i,:,:,:] = img_aug\n",
    "\n",
    "        # Augmentation number 8: 270° rotation + vertical flip +\n",
    "        # horizontal flip\n",
    "        img_aug = tf.image.rot90(img_array[i], k=3).numpy()\n",
    "        img_aug = tf.image.flip_up_down(img_aug).numpy()\n",
    "        img_aug = tf.image.flip_left_right(img_aug).numpy()\n",
    "        img_array_full[8,i,:,:,:] = img_aug\n",
    "\n",
    "        # Augmentation number 9: vertical flip + horizontal flip\n",
    "        img_aug = tf.image.flip_up_down(img_array[i]).numpy()\n",
    "        img_aug = tf.image.flip_left_right(img_aug).numpy()\n",
    "        img_array_full[9,i,:,:,:] = img_aug\n",
    "\n",
    "        # Augmentation number 10: vertical flip\n",
    "        img_aug = tf.image.flip_up_down(img_array[i]).numpy()\n",
    "        img_array_full[10,i,:,:,:] = img_aug\n",
    "\n",
    "        # Augmentation number 11: horizontal flip\n",
    "        img_aug = tf.image.flip_left_right(img_array[i]).numpy()\n",
    "        img_array_full[11,i,:,:,:] = img_aug\n",
    "\n",
    "        # Report progress\n",
    "        if (i%1000 == 0) & (i != 0):\n",
    "            print(' - ' + str(round(100*i/img_array.shape[0])) + \n",
    "            '% of all images have been augmented.')\n",
    "        elif (i%100 == 0) & (i != 0):\n",
    "            print('.', end='')\n",
    "    return img_array_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting training images\n",
      "......... - 15% of all images have been augmented.\n",
      "......... - 29% of all images have been augmented.\n",
      "......... - 44% of all images have been augmented.\n",
      "......... - 59% of all images have been augmented.\n",
      "......... - 73% of all images have been augmented.\n",
      "......... - 88% of all images have been augmented.\n",
      "........\n",
      "Augmenting labels\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Augment data\n",
    "print('Augmenting training images')\n",
    "img_train_full = augment_images(img_train)\n",
    "print('\\nAugmenting labels')\n",
    "labels_train_full = np.tile(labels_train, (12,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reshape augmented data\n",
    "img_train = np.reshape(img_train_full, (-1,35,35,4))\n",
    "labels_train = np.reshape(labels_train_full, (-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many more pictures did we get by augmenting the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81744, 35, 35, 4)\n"
     ]
    }
   ],
   "source": [
    "print(img_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81744,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversample the data\n",
    "We oversample the training data by randomly picking images until all classes have the same amount of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the frequency of each class in the data\n",
    "_, n_all = np.unique(labels_train, return_counts=True)\n",
    "\n",
    "# Determine the class with the most data\n",
    "n_max = np.max(n_all)\n",
    "\n",
    "# Generate a new array that contains the oversampled image results\n",
    "img_train_os = img_train.copy()\n",
    "\n",
    "# Generate a new array that contains the oversampled label results\n",
    "labels_train_os = labels_train.copy()\n",
    "\n",
    "# Loop through all class categories\n",
    "for i in range(len(n_all)):\n",
    "\n",
    "    # Extract the frequency of this class\n",
    "    n_class = n_all[i]\n",
    "\n",
    "    # Execute this code if this is not the class with the highest\n",
    "    # frequency\n",
    "    if (n_class != n_max):\n",
    "\n",
    "        # Extract only images of this class\n",
    "        img_class = img_train[labels_train == i]\n",
    "\n",
    "        # Extract only labels of this class\n",
    "        label_class = labels_train[labels_train == i]\n",
    "\n",
    "        # Generate as many random integers as there are in the class\n",
    "        # category with the highest frequency minus the number of already\n",
    "        # existing images for this class category\n",
    "        rand_ind = np.random.randint(0, img_class.shape[0]-1,\n",
    "                                     n_max - n_class)\n",
    "\n",
    "        # Draw random images from the existing images\n",
    "        img_rand = img_class[rand_ind,:,:,:]\n",
    "\n",
    "        # Draw the very same random labels\n",
    "        label_rand = label_class[rand_ind]\n",
    "\n",
    "        # Append those copied images to the image array\n",
    "        img_train_os = np.append(img_train_os, img_rand, axis=0)\n",
    "\n",
    "        # Append the very same random labels to the labels array\n",
    "        labels_train_os = np.append(labels_train_os, label_rand, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the size of the training sets before and after oversampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81744, 35, 35, 4)\n",
      "(181824, 35, 35, 4)\n"
     ]
    }
   ],
   "source": [
    "print(img_train.shape)\n",
    "print(img_train_os.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encode the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train_os = tf.keras.utils.to_categorical(labels_train_os)\n",
    "labels_test = tf.keras.utils.to_categorical(labels_test)\n",
    "labels_val = tf.keras.utils.to_categorical(labels_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are done and can save the data back to a `.npz` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"./data/data_preprocessed\",img_train=img_train_os,labels_train=labels_train_os,img_test=img_test,labels_test=labels_test,img_val=img_val,labels_val=labels_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
