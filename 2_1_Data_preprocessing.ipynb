{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 Data Preprocessing\n",
    "In this Notebook we will preprocess the data we generated earlier. We will:\n",
    "- [Categorize trees into the 4 classes](#loading-relabeling-the-data-and-encoding-the-data)\n",
    "- [Split the data into training, validation and test sets](#spliting-the-data-into-training-validation-and-test-sets)\n",
    "- [Apply data augmentation techniques](#perform-data-augmentation)\n",
    "- [Perform oversampling](#oversample-the-data)\n",
    "- [One-hot encode the labels](#one-hot-encode-the-labels)\n",
    "\n",
    "__Note:__ For demonstration purposes we will only process the TDOP data in this Notebook. In the `scripts` folder is a file containing all the functions to use the process on all available data. \n",
    "The data used in this notebook is a `.npz` file that contains 2 arrays: 1 with images from all years available and the associated labels. The procedure used is explained in [\"1_2_tree_extraction_to_numpy\"](./1_2_tree_extraction_to_numpy.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing needed libraries & packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading, relabeling the data and encoding the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the data file\n",
    "data_path = './data/TDOP.npz'\n",
    "\n",
    "# Load the image array containing all box images in a 4D array and their\n",
    "# labels\n",
    "with np.load(data_path, allow_pickle=True) as data:\n",
    "    img_array = data[\"img\"]\n",
    "    labels = data[\"labels\"]\n",
    "\n",
    "# the next lines assume we extracted images from multiple years, but moving forward we only use the data from one year\n",
    "img_array = img_array[[4,4,4,4,4],:,:,:,:] \n",
    "labels = labels[[4,4,4,4,4],:].astype(\"object\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow prefers integers as target values, therefore we have to transform our labels.\n",
    " \n",
    "As a first step, create a new array filled with zeros and in the same shape as the \"labels\". \n",
    "The we replace all zeros with integers as in the position where one of the 3 tree species of interest are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_int = np.zeros_like(labels)\n",
    "\n",
    "# Loop through each label\n",
    "for i in range(len(labels[1])):\n",
    "    \n",
    "    # Assign a 1 if it is a Rotbuche\n",
    "    if labels[1][i] == 'Rotbuche':\n",
    "        labels_int[:,i] = 1\n",
    "\n",
    "    # Assign a 2 if it is Ahorn    \n",
    "    elif labels[1][i] == 'Berg-Ahorn' or labels[1][i] == 'Feld-Ahorn':\n",
    "        labels_int[:,i] = 2\n",
    "\n",
    "    # Assign a 3 if it is a Birke    \n",
    "    elif labels[1][i] == 'Haenge-Birke' or labels[1][i] == 'Moor-Birke':\n",
    "        labels_int[:,i] = 3\n",
    "    \n",
    "# The array is still of type \"obj\", we need to change it to \"int\"\n",
    "labels_int = labels_int.astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will do the one-hot encoding later just before saving the preprocessed data for the model. What we will do now is normalizing our 16-bit image data to the 0 - 1 range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_array = tf.keras.utils.normalize(img_array, axis=-1, order=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what we produced so far:\n",
    "\n",
    "For the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of our data: (5, 1705, 35, 35, 4)\n",
      "\n",
      "One image: [[[0.30684337 0.35457359 0.30616927 0.82848361]\n",
      "  [0.31140532 0.35969456 0.31073823 0.82285376]\n",
      "  [0.29702489 0.34498832 0.29423767 0.84034723]\n",
      "  ...\n",
      "  [0.25336822 0.28991713 0.27877118 0.87979499]\n",
      "  [0.26146351 0.29894882 0.28767522 0.87149837]\n",
      "  [0.26575367 0.30709814 0.28030872 0.86976591]]\n",
      "\n",
      " [[0.32896587 0.37892155 0.32426018 0.80190726]\n",
      "  [0.32604895 0.3762563  0.3178006  0.80692383]\n",
      "  [0.31031191 0.35905637 0.30290574 0.8264582 ]\n",
      "  ...\n",
      "  [0.24979537 0.28687163 0.27004837 0.88452294]\n",
      "  [0.23959871 0.2753487  0.26011014 0.89393415]\n",
      "  [0.26435675 0.30571324 0.27923974 0.87102244]]\n",
      "\n",
      " [[0.33949419 0.39086741 0.33333975 0.78794097]\n",
      "  [0.3458533  0.39845726 0.32997026 0.78277515]\n",
      "  [0.32754419 0.37841204 0.31457749 0.80657308]\n",
      "  ...\n",
      "  [0.25662003 0.29638248 0.26983392 0.87948464]\n",
      "  [0.25080152 0.28914938 0.26430217 0.88523194]\n",
      "  [0.28009484 0.3256136  0.2853882  0.85678249]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.35735836 0.38858502 0.27039899 0.80509694]\n",
      "  [0.34470794 0.37611716 0.26631427 0.81779523]\n",
      "  [0.34584636 0.37807859 0.27255619 0.81434636]\n",
      "  ...\n",
      "  [0.30219612 0.32082164 0.28352433 0.85168359]\n",
      "  [0.31096807 0.33233426 0.28715636 0.84284876]\n",
      "  [0.31867299 0.34261152 0.28936581 0.83506425]]\n",
      "\n",
      " [[0.3541986  0.38730465 0.26812589 0.80786569]\n",
      "  [0.35278749 0.38557323 0.2683194  0.80924593]\n",
      "  [0.34861346 0.38103599 0.27080574 0.81236967]\n",
      "  ...\n",
      "  [0.32213471 0.34202194 0.2986159  0.8307098 ]\n",
      "  [0.31169745 0.33699677 0.28725782 0.84069068]\n",
      "  [0.32525699 0.35578842 0.29732281 0.82414904]]\n",
      "\n",
      " [[0.34647542 0.37984888 0.26529203 0.81565296]\n",
      "  [0.35103276 0.38442206 0.27002636 0.80998855]\n",
      "  [0.35161187 0.38499908 0.27449548 0.80795856]\n",
      "  ...\n",
      "  [0.33096345 0.35445463 0.30463397 0.81977024]\n",
      "  [0.32381378 0.35252492 0.2974267  0.82608   ]\n",
      "  [0.32600744 0.36029667 0.29862801 0.82141753]]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of our data: \" + str(img_array.shape)+ \"\\n\")\n",
    "print(\"One image: \" + str(img_array[0,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And for the labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 3, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_int[0,:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting the data into training, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking how many channels the image data has, 4 for standard RGB+IR TDOP images, 3 would be RGB only\n",
    "nr_channels = img_array.shape[-1]\n",
    "\n",
    "# Reshape the arrays \n",
    "reshaped_img = img_array.reshape(-1, 35, 35, nr_channels)\n",
    "reshaped_labels = labels_int.reshape(-1)\n",
    "\n",
    "# Setting the split ratios\n",
    "train_size = 0.8\n",
    "val_size = 0.1\n",
    "test_size =  val_size / (1 - train_size)\n",
    "# Generate indices for splitting\n",
    "idx_train, idx_temp, labels_train, labels_temp = train_test_split(np.arange(len(reshaped_img)), reshaped_labels, train_size=train_size, stratify=reshaped_labels)\n",
    "idx_val, idx_test, labels_val, labels_test = train_test_split(idx_temp, labels_temp, test_size=test_size, stratify=labels_temp)\n",
    "\n",
    "# Split the data and reshape back\n",
    "img_train = reshaped_img[idx_train]\n",
    "img_val = reshaped_img[idx_val]\n",
    "img_test = reshaped_img[idx_test]\n",
    "\n",
    "# Reshape labels arrays\n",
    "labels_train = labels_train.reshape(-1)\n",
    "labels_val = labels_val.reshape(-1)\n",
    "labels_test = labels_test.reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again lets see how the different sets look like now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6820, 35, 35, 4)\n",
      "(6820,)\n"
     ]
    }
   ],
   "source": [
    "print(img_train.shape)\n",
    "print(labels_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that takes a dataset of images and augments each image\n",
    "# once in a certain way\n",
    "def augment_images(img_array):\n",
    "\n",
    "    # Predefine an array that will contain the augmented images\n",
    "    img_array_full = np.tile(img_array, (12,1,1,1,1))\n",
    "\n",
    "    # Loop through each image\n",
    "    for i in range(img_array.shape[0]):\n",
    "\n",
    "        # Augmentation number 0: Nothing\n",
    "        img_aug = img_array_full[0,i,:,:,:]\n",
    "        img_array_full[0,i,:,:,:] = img_aug\n",
    "\n",
    "        # Augmentation number 1: 90° rotation        \n",
    "        img_aug = tf.image.rot90(img_array[i], k=1).numpy()\n",
    "        img_array_full[1,i,:,:,:] = img_aug\n",
    "\n",
    "        # Augmentation number 2: 90° rotation + vertical flip\n",
    "        img_aug = tf.image.rot90(img_array[i], k=1).numpy()\n",
    "        img_aug = tf.image.flip_up_down(img_aug).numpy()\n",
    "        img_array_full[2,i,:,:,:] = img_aug\n",
    "\n",
    "        # Augmentation number 3: 90° rotation + horizontal flip\n",
    "        img_aug = tf.image.rot90(img_array[i], k=1).numpy()\n",
    "        img_aug = tf.image.flip_left_right(img_aug).numpy()\n",
    "        img_array_full[3,i,:,:,:] = img_aug\n",
    "\n",
    "        # Augmentation number 4: 90° rotation + vertical flip +\n",
    "        # horizontal flip\n",
    "        img_aug = tf.image.rot90(img_array[i], k=1).numpy()\n",
    "        img_aug = tf.image.flip_up_down(img_aug).numpy()\n",
    "        img_aug = tf.image.flip_left_right(img_aug).numpy()\n",
    "        img_array_full[4,i,:,:,:] = img_aug\n",
    "\n",
    "        # Augmentation number 5: 270° rotation\n",
    "        img_aug = tf.image.rot90(img_array[i], k=3).numpy()\n",
    "        img_array_full[5,i,:,:,:] = img_aug\n",
    "\n",
    "        # Augmentation number 6: 270° rotation + vertical flip\n",
    "        img_aug = tf.image.rot90(img_array[i], k=3).numpy()\n",
    "        img_aug = tf.image.flip_up_down(img_aug).numpy()\n",
    "        img_array_full[6,i,:,:,:] = img_aug\n",
    "\n",
    "        # Augmentation number 7: 90° rotation + horizontal flip\n",
    "        img_aug = tf.image.rot90(img_array[i], k=3).numpy()\n",
    "        img_aug = tf.image.flip_left_right(img_aug).numpy()\n",
    "        img_array_full[7,i,:,:,:] = img_aug\n",
    "\n",
    "        # Augmentation number 8: 270° rotation + vertical flip +\n",
    "        # horizontal flip\n",
    "        img_aug = tf.image.rot90(img_array[i], k=3).numpy()\n",
    "        img_aug = tf.image.flip_up_down(img_aug).numpy()\n",
    "        img_aug = tf.image.flip_left_right(img_aug).numpy()\n",
    "        img_array_full[8,i,:,:,:] = img_aug\n",
    "\n",
    "        # Augmentation number 9: vertical flip + horizontal flip\n",
    "        img_aug = tf.image.flip_up_down(img_array[i]).numpy()\n",
    "        img_aug = tf.image.flip_left_right(img_aug).numpy()\n",
    "        img_array_full[9,i,:,:,:] = img_aug\n",
    "\n",
    "        # Augmentation number 10: vertical flip\n",
    "        img_aug = tf.image.flip_up_down(img_array[i]).numpy()\n",
    "        img_array_full[10,i,:,:,:] = img_aug\n",
    "\n",
    "        # Augmentation number 11: horizontal flip\n",
    "        img_aug = tf.image.flip_left_right(img_array[i]).numpy()\n",
    "        img_array_full[11,i,:,:,:] = img_aug\n",
    "\n",
    "        # Report progress\n",
    "        if (i%1000 == 0) & (i != 0):\n",
    "            print(' - ' + str(round(100*i/img_array.shape[0])) + \n",
    "            '% of all images have been augmented.')\n",
    "        elif (i%100 == 0) & (i != 0):\n",
    "            print('.', end='')\n",
    "    return img_array_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting training images\n",
      "......... - 15% of all images have been augmented.\n",
      "......... - 29% of all images have been augmented.\n",
      "......... - 44% of all images have been augmented.\n",
      "......... - 59% of all images have been augmented.\n",
      "......... - 73% of all images have been augmented.\n",
      "......... - 88% of all images have been augmented.\n",
      "........\n",
      "Augmenting labels\n"
     ]
    }
   ],
   "source": [
    "# Augment data\n",
    "print('Augmenting training images')\n",
    "img_train_full = augment_images(img_train)\n",
    "print('\\nAugmenting labels')\n",
    "labels_train_full = np.tile(labels_train, (12,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape augmented data\n",
    "img_train = np.reshape(img_train_full, (-1,35,35,4))\n",
    "labels_train = np.reshape(labels_train_full, (-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many more pictures did we get by augmenting the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81840, 35, 35, 4)\n"
     ]
    }
   ],
   "source": [
    "print(img_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81840,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversample the data\n",
    "We oversample the training data by randomly picking images until all classes have the same amount of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the frequency of each class in the data\n",
    "_, n_all = np.unique(labels_train, return_counts=True)\n",
    "\n",
    "# Determine the class with the most data\n",
    "n_max = np.max(n_all)\n",
    "\n",
    "# Generate a new array that contains the oversampled image results\n",
    "img_train_os = img_train.copy()\n",
    "\n",
    "# Generate a new array that contains the oversampled label results\n",
    "labels_train_os = labels_train.copy()\n",
    "\n",
    "# Loop through all class categories\n",
    "for i in range(len(n_all)):\n",
    "\n",
    "    # Extract the frequency of this class\n",
    "    n_class = n_all[i]\n",
    "\n",
    "    # Execute this code if this is not the class with the highest\n",
    "    # frequency\n",
    "    if (n_class != n_max):\n",
    "\n",
    "        # Extract only images of this class\n",
    "        img_class = img_train[labels_train == i]\n",
    "\n",
    "        # Extract only labels of this class\n",
    "        label_class = labels_train[labels_train == i]\n",
    "\n",
    "        # Generate as many random integers as there are in the class\n",
    "        # category with the highest frequency minus the number of already\n",
    "        # existing images for this class category\n",
    "        rand_ind = np.random.randint(0, img_class.shape[0]-1,\n",
    "                                     n_max - n_class)\n",
    "\n",
    "        # Draw random images from the existing images\n",
    "        img_rand = img_class[rand_ind,:,:,:]\n",
    "\n",
    "        # Draw the very same random labels\n",
    "        label_rand = label_class[rand_ind]\n",
    "\n",
    "        # Append those copied images to the image array\n",
    "        img_train_os = np.append(img_train_os, img_rand, axis=0)\n",
    "\n",
    "        # Append the very same random labels to the labels array\n",
    "        labels_train_os = np.append(labels_train_os, label_rand, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the size of the training sets before and after oversampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81840, 35, 35, 4)\n",
      "(182016, 35, 35, 4)\n"
     ]
    }
   ],
   "source": [
    "print(img_train.shape)\n",
    "print(img_train_os.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encode the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train_os = tf.keras.utils.to_categorical(labels_train_os)\n",
    "labels_test = tf.keras.utils.to_categorical(labels_test)\n",
    "labels_val = tf.keras.utils.to_categorical(labels_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are done and can save the data back to a `.npz` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"./data/data_preprocessed\",img_train=img_train_os,labels_train=labels_train_os,img_test=img_test,labels_test=labels_test,img_val=img_val,labels_val=labels_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
